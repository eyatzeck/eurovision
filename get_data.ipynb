{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this module\n",
    "\n",
    "The module scrapes Eurovision data off of the main site which stores that data, which is https://eschome.net/index.html\n",
    "\n",
    "The structure of the site is to provide the user with various slices of the data, which are presented in html tables.  No direct access to the underlying data is available.\n",
    "\n",
    "At first glance, it seems like eschome.net is dynamically rendering the data in a way that will make it hard to scrape, but as you investigate the site, it turns out you can reverse-engineer the html POST operations which render the data pages, so even though the actual database calls are hidden in some php code, you can treat the resulting pages as static html.\n",
    "\n",
    "This allows the data scraping to be done very efficiently using the pandas read_html() function, which locates tables on web pages and puts them into dataframes.\n",
    "\n",
    "The data of interest for this presentation is:\n",
    "\n",
    "* List of every Eurovision final (reference)\n",
    "\n",
    "* List of years, countries that participated in the finals that year, the order in which they performed in the finals, and how they placed. (to allow analysis of how important it is which order you perform in)\n",
    "\n",
    "* List of years, participant countries, and how they voted (to allow analysis of block voting, like \"all the Baltic countries vote together\")\n",
    "\n",
    "__I've put a variable called \"is_refresh\" around all of the code to avoid needlessly re-scraping the site, which only changes once per year, and then, only to add.  Set is_refresh to True at the top of the code to re-scrape.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all the finals, and where they were hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO as SIO\n",
    "\n",
    "is_refresh = False\n",
    "\n",
    "if is_refresh == True:\n",
    "\n",
    "    # url generated by eschome.net when you click on \"List of all Final Events\" (no details)\n",
    "    url = 'https://eschome.net/databaseoutput410.php'\n",
    "\n",
    "    # get the full page text\n",
    "    page = requests.post(url)\n",
    "\n",
    "    # create a list of tables\n",
    "    list_of_tables = pd.read_html(SIO(page.text), header = 0)\n",
    "\n",
    "    # assign second table to dataframe and keep only the interesting columns\n",
    "    df = list_of_tables[1]\n",
    "    all_finals = df[['Year','Country','City','Location','Broadcaster','Date']]\n",
    "    print(\"Imported \" + str(len(all_finals)) + \" finals records.\")\n",
    "    all_finals.to_csv('all_finals.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of what the order and placement was for all finals participants for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 1399 years of finals placement records.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO as SIO\n",
    "\n",
    "is_refresh = False\n",
    "\n",
    "if is_refresh == True:\n",
    "    # set base url\n",
    "    url = 'https://eschome.net/databaseoutput401.php'\n",
    "\n",
    "    # use list of years from previous step\n",
    "    \n",
    "    # loop through all years to get list of results plus order of performance\n",
    "    for index, row in all_finals.iterrows():\n",
    "        print(\"Importing results for \" + str(row['Year']) + \"...\")\n",
    "        # set year\n",
    "        if(row['Year'] < 2004):\n",
    "            jahr = str(row['Year'])\n",
    "        else:\n",
    "            jahr = str(row['Year'])+\"F\"\n",
    "\n",
    "        # get all the pages and append to all_votes\n",
    "        params = {'jahr' : jahr, 'x' : '6', 'y' : '6'}\n",
    "        page = requests.post(url,data = params,allow_redirects=False)\n",
    "\n",
    "        # create a list of tables\n",
    "        list_of_tables = pd.read_html(SIO(page.text), header = 0)\n",
    "        if(len(list_of_tables) < 2):\n",
    "            print(\"error - no tables found on this page.\")\n",
    "            continue\n",
    "\n",
    "        df = list_of_tables[1][['Place','Points','No.','Country']].copy()\n",
    "        df['Year'] = str(row['Year'])\n",
    "        df = df[['Year','Place','Points','No.','Country']]\n",
    "        df.rename(columns={'No.': 'Order'}, inplace=True)\n",
    "                \n",
    "        if(index == 0):\n",
    "            all_placements = df.copy()\n",
    "        else:\n",
    "            all_placements = pd.concat([all_placements, df], ignore_index=True)\n",
    "        \n",
    "        print(\"Running total of \" + str(len(all_placements)) + \" years of finals placement records imported.\")\n",
    "        print(all_placements.tail(1))\n",
    "else:\n",
    "    all_placements = pd.read_csv('all_placements.csv')\n",
    "    print(\"Imported \" + str(len(all_placements)) + \" years of finals placement records.\")\n",
    "\n",
    "#convert all numeric columns to integer and save to csv\n",
    "all_placements['Place'] = all_placements['Place'].fillna(0)\n",
    "all_placements['Points'] = all_placements['Points'].fillna(0)\n",
    "all_placements['Order'] = all_placements['Order'].fillna(0)\n",
    "all_placements = all_placements.astype({'Year': 'int32', 'Place': 'int32', 'Points': 'int32', 'Order': 'int32'})\n",
    "\n",
    "# assign max order to each row in all_placements\n",
    "all_placements['MaxOrder'] = all_placements.groupby('Year')['Order'].transform('max')\n",
    "all_placements['AdjOrder'] = round((all_placements['MaxOrder'] * all_placements['Order'])/26)\n",
    "all_placements.to_csv('all_placements.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of who voted for whom over time and with how many points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 49162 years of finals placement records.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO as SIO\n",
    "\n",
    "if is_refresh == True:\n",
    "\n",
    "    # set base url\n",
    "    url = 'https://eschome.net/databaseoutput403.php'\n",
    "\n",
    "    # get list of countries\n",
    "    # note:  country list was pulled from source code of https://eschome.net/index.html and massaged in excel\n",
    "    countries = pd.read_csv('all_countries.csv')\n",
    "\n",
    "    # loop through all countries to get all votes from all other countries\n",
    "    for reciever_index, receiver_row in countries.iterrows():\n",
    "        for giver_index, giver_row in countries.iterrows():\n",
    "            \n",
    "            # countries are not allowed to vote for themselves.\n",
    "            if( reciever_index == giver_index ):\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                print(\"Importing ratings for \" + receiver_row['Name'] + \" from \" + giver_row['Name'] + \"...\")\n",
    "\n",
    "                # get all the pages and append to all_votes\n",
    "                params = {'land_erhalten' : receiver_row['Code'], 'land_gegeben' : giver_row['Code'], 'x' : '7', 'y' : '3'}\n",
    "                page = requests.post(url,data = params,allow_redirects=False)\n",
    "\n",
    "                # create a list of tables\n",
    "                list_of_tables = pd.read_html(SIO(page.text), header = 0)\n",
    "                if(len(list_of_tables) < 2):\n",
    "                    print(\"error - no tables found on this page.\")\n",
    "                    continue\n",
    "\n",
    "                # create dataframe if it doesn't exist yet, otherwise append\n",
    "                df = list_of_tables[1][['Year','Type','Points']].copy()\n",
    "                df['Receiver'] = receiver_row['Code']\n",
    "                df['Giver'] = giver_row['Code']\n",
    "                df = df[['Giver','Receiver','Year','Type','Points']]\n",
    "                        \n",
    "                if(reciever_index == 0 and giver_index == 1):\n",
    "                    all_votes = df.copy()\n",
    "                else:\n",
    "                    all_votes = pd.concat([all_votes, df], ignore_index=True)\n",
    "                \n",
    "                print(\"Running total of \" + str(len(all_votes)) + \" vote records imported.\")\n",
    "                print(all_votes)\n",
    "\n",
    "\n",
    "else:\n",
    "    all_votes = pd.read_csv('all_votes.csv')\n",
    "    print(\"Imported \" + str(len(all_votes)) + \" years of finals placement records.\")\n",
    "\n",
    "#convert all numeric columns to integer and save to csv\n",
    "all_votes['Year'] = all_votes['Year'].fillna(0)\n",
    "all_votes['Points'] = all_votes['Points'].fillna(0)\n",
    "all_votes['Type'] = all_votes['Type'].fillna('F')\n",
    "all_votes = all_votes.astype({'Year': 'int32', 'Points': 'int32'})\n",
    "#save to csv\n",
    "all_votes.to_csv('all_votes.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
