{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this module\n",
    "\n",
    "The module scrapes Eurovision data off of the main site which stores that data, which is https://eschome.net/index.html\n",
    "\n",
    "The structure of the site is to provide the user with various slices of the data, which are presented in html tables.  No direct access to the underlying data is available.\n",
    "\n",
    "At first glance, it seems like eschome.net is dynamically rendering the data in a way that will make it hard to scrape, but as you investigate the site, it turns out you can reverse-engineer the html POST operations which render the data, so even though the actual database calls are hidden in some php code, you can treat the resulting pages as static html.\n",
    "\n",
    "The data of interest for this presentation is:\n",
    "\n",
    "* List of every Eurovision final (reference)\n",
    "\n",
    "* List of years, countries that participated in the finals that year, the order in which they performed in the finals, and how they placed. (to allow analysis of how important it is which order you perform in)\n",
    "\n",
    "* List of years, participant countries, and how they voted (to allow analysis of block voting, like \"all the Baltic countries vote together\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 67 finals records.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO as SIO\n",
    "\n",
    "# url generated by eschome.net when you click on \"List of all Final Events\" (no details)\n",
    "url = 'https://eschome.net/databaseoutput410.php'\n",
    "\n",
    "# get the full page text\n",
    "page = requests.post(url)\n",
    "\n",
    "# create a list of tables\n",
    "list_of_tables = pd.read_html(SIO(page.text), header = 0)\n",
    "\n",
    "# assign second table to dataframe and keep only the interesting columns\n",
    "df = list_of_tables[1]\n",
    "all_cols = df[['Year','Country','City','Location','Broadcaster','Date']]\n",
    "print(\"Imported \" + str(len(all_cols)) + \" finals records.\")\n",
    "all_cols.to_csv('all_finals.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
